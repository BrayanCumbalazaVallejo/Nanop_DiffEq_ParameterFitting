{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Cargar datos\n",
    "data = pd.read_csv(\"../files/input/experiment_data.csv\")\n",
    "\n",
    "# ANOVA\n",
    "f_stat, p_value = f_oneway(data[\"Absorbance_Exp1\"], data[\"Absorbance_Exp2\"], data[\"Absorbance_Exp3\"])\n",
    "\n",
    "# Resultados\n",
    "print(f\"F-statistic: {f_stat}, p-value: {p_value}\")\n",
    "print(\"Conclusión:\", \"Diferencias significativas\" if p_value < 0.05 else \"No hay diferencias significativas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reformatear los datos para suavizado\n",
    "data_melted = data.melt(id_vars=[\"Time (min)\"], var_name=\"Experiment\", value_name=\"Absorbance\")\n",
    "data_melted[\"Experiment\"] = data_melted[\"Experiment\"].str.extract(r'(\\d)').astype(int)\n",
    "\n",
    "# Configuración para el suavizado\n",
    "n_corridas = 3\n",
    "n_puntos_por_corrida = len(data_melted) // n_corridas\n",
    "window_length = 20  # Longitud de la ventana (debe ser impar)\n",
    "polyorder = 2  # Orden del polinomio\n",
    "\n",
    "# Reestructurar los datos en corridas\n",
    "data_melted[\"Group\"] = data_melted.groupby(\"Experiment\").cumcount() // n_puntos_por_corrida\n",
    "\n",
    "# Aplicar el filtro Savitzky-Golay para cada corrida\n",
    "data_melted[\"Smoothed\"] = data_melted.groupby([\"Experiment\", \"Group\"])[\"Absorbance\"].transform(\n",
    "    lambda x: savgol_filter(x, window_length, polyorder) if len(x) >= window_length else x\n",
    ")\n",
    "\n",
    "# Calcular el promedio suavizado\n",
    "promedio_suavizado = data_melted.groupby(\"Time (min)\")[\"Smoothed\"].mean().reset_index()\n",
    "promedio_suavizado.rename(columns={\"Smoothed\": \"Average Smoothed\"}, inplace=True)\n",
    "\n",
    "# Graficar datos originales y suavizados\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Graficar cada experimento original y suavizado\n",
    "for exp in data_melted[\"Experiment\"].unique():\n",
    "    exp_data = data_melted[data_melted[\"Experiment\"] == exp]\n",
    "    plt.plot(exp_data[\"Time (min)\"], exp_data[\"Absorbance\"], 'o', alpha=0.5, label=f'Exp {exp} (Original)')\n",
    "    plt.plot(exp_data[\"Time (min)\"], exp_data[\"Smoothed\"], '-', label=f'Exp {exp} (Suavizado)')\n",
    "\n",
    "# Graficar promedio suavizado\n",
    "plt.plot(promedio_suavizado[\"Time (min)\"], promedio_suavizado[\"Average Smoothed\"], 'k--', linewidth=2, label='Promedio Suavizado')\n",
    "\n",
    "# Configuración de la gráfica\n",
    "plt.title('Promedio Suavizado de Datos de Absorbancia con Savitzky-Golay (Pandas)')\n",
    "plt.xlabel('Tiempo (min)')\n",
    "plt.ylabel('Absorbancia (u.a.)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Ruta del directorio de salida\n",
    "output_dir = \"../files/output\"\n",
    "\n",
    "# Verificar si el directorio de salida existe, si no, crearlo\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Guardar únicamente tiempo y promedio suavizado en el DataFrame final\n",
    "promedio_suavizado.to_csv(os.path.join(output_dir, \"data_clean.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Crear el directorio de modelos si no existe\n",
    "models_dir = \"../files/models\"\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "    print(f\"Directorio creado: {models_dir}\")\n",
    "\n",
    "# Cargar los datos experimentales\n",
    "df = pd.read_csv(\"../files/output/data_clean.csv\")\n",
    "t = df[\"Time (min)\"].values\n",
    "A = df[\"Average Smoothed\"].values\n",
    "\n",
    "n_train = 13  # Número de puntos para el ajuste\n",
    "el = 1416.536  # Absortividad molar por cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo\n",
    "def model_1(t, Ag, k, p_td):\n",
    "    return el * (p_td * np.exp(-k * t) + Ag * (1 - np.exp(-k * t)))\n",
    "\n",
    "# Ajustar el modelo\n",
    "t_fit = t[:n_train]\n",
    "A_fit = A[:n_train]\n",
    "\n",
    "initial_guess = [0.0018, 1, 0.00018]\n",
    "bounds = ([0, 0, 0], [np.inf, np.inf, np.inf])\n",
    "\n",
    "params, covariance = curve_fit(model_1, t_fit, A_fit, p0=initial_guess, bounds=bounds)\n",
    "\n",
    "# Guardar los parámetros y el modelo en el Pickle\n",
    "model_data = {\n",
    "    \"parameters\": params,\n",
    "    \"covariance\": covariance,\n",
    "    \"model\": model_1  # Incluir la función del modelo\n",
    "}\n",
    "\n",
    "model_path = os.path.join(models_dir, \"model_1.pkl\")\n",
    "with open(model_path, \"wb\") as file:\n",
    "    pickle.dump(model_data, file)\n",
    "\n",
    "print(f\"Modelo guardado en: {model_path}\")\n",
    "print(\"Parámetros ajustados:\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo\n",
    "def model_2(t, p_td, theta, k):\n",
    "    return el * (p_td + theta * (1 - np.exp(-k * t)))\n",
    "\n",
    "# Ajustar el modelo\n",
    "t_fit = t[:n_train]\n",
    "A_fit = A[:n_train]\n",
    "\n",
    "initial_guess = [0.0018, 1, 0.00018]\n",
    "bounds = ([0, 0, 0], [np.inf, np.inf, np.inf])\n",
    "\n",
    "params, covariance = curve_fit(model_2, t_fit, A_fit, p0=initial_guess, bounds=bounds)\n",
    "\n",
    "# Guardar los parámetros y el modelo en el Pickle\n",
    "model_data = {\n",
    "    \"parameters\": params,\n",
    "    \"covariance\": covariance,\n",
    "    \"model\": model_2  # Incluir la función del modelo\n",
    "}\n",
    "\n",
    "model_path = os.path.join(models_dir, \"model_2.pkl\")\n",
    "with open(model_path, \"wb\") as file:\n",
    "    pickle.dump(model_data, file)\n",
    "\n",
    "print(f\"Modelo guardado en: {model_path}\")\n",
    "print(\"Parámetros ajustados:\", params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo\n",
    "def model_3(t, beta, k, x1, y1):\n",
    "    return el * (x1 + y1 * np.log(np.abs(1 + beta) / (np.exp(-k * t) + beta)))\n",
    "\n",
    "# Ajustar el modelo\n",
    "t_fit = t[:n_train]\n",
    "A_fit = A[:n_train]\n",
    "\n",
    "initial_guess = [2.81547, 0.02725, 9.0226e-05, 0.00416]\n",
    "bounds = ([2, 0.02, 0, 0], [3, 0.02725, 9.0226e-05, 0.00416])\n",
    "\n",
    "params, covariance = curve_fit(model_3, t_fit, A_fit, p0=initial_guess, bounds=bounds)\n",
    "\n",
    "# Guardar los parámetros y el modelo en el Pickle\n",
    "model_data = {\n",
    "    \"parameters\": params,\n",
    "    \"covariance\": covariance,\n",
    "    \"model\": model_3  # Incluir la función del modelo\n",
    "}\n",
    "\n",
    "model_path = os.path.join(models_dir, \"model_3.pkl\")\n",
    "with open(model_path, \"wb\") as file:\n",
    "    pickle.dump(model_data, file)\n",
    "\n",
    "print(f\"Modelo guardado en: {model_path}\")\n",
    "print(\"Parámetros ajustados:\", params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import lambertw\n",
    "\n",
    "# Definir el modelo 4\n",
    "def model_4(t, c1, k, x1, y1):\n",
    "    epsilon = 1416.536\n",
    "    return epsilon * (x1 - y1 * np.real(lambertw(c1 * np.exp(-k * t))))\n",
    "\n",
    "# Ajustar el modelo\n",
    "t_fit = t[:n_train]\n",
    "A_fit = A[:n_train]\n",
    "\n",
    "initial_guess = [0.15, 0.027, 0.001356, 0.00839]\n",
    "bounds = ([0, 0.026, 0.001355, 0.00838], [0.3, 0.028, 0.001357, 0.00840])  # Margen ajustado\n",
    "\n",
    "params, covariance = curve_fit(model_4, t_fit, A_fit, p0=initial_guess, bounds=bounds)\n",
    "\n",
    "# Guardar los parámetros y el modelo en el Pickle\n",
    "model_data = {\n",
    "    \"parameters\": params,\n",
    "    \"covariance\": covariance,\n",
    "    \"model\": model_4  # Incluir la función del modelo\n",
    "}\n",
    "\n",
    "model_path = os.path.join(models_dir, \"model_4.pkl\")\n",
    "with open(model_path, \"wb\") as file:\n",
    "    pickle.dump(model_data, file)\n",
    "\n",
    "print(f\"Modelo guardado en: {model_path}\")\n",
    "print(\"Parámetros ajustados:\", params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def graf_and_save(model_pickle_path, data_path, output_dir, n_train):\n",
    "    \"\"\"\n",
    "    Genera una gráfica personalizada entre datos experimentales, modelo ajustado y predicciones,\n",
    "    y muestra el valor de R^2 directamente en la gráfica.\n",
    "    \n",
    "    Parameters:\n",
    "        model_pickle_path (str): Ruta al archivo Pickle con el modelo ajustado.\n",
    "        data_path (str): Ruta al archivo CSV con los datos experimentales.\n",
    "        output_dir (str): Directorio donde se guardará la gráfica.\n",
    "        n_train (int): Número de puntos utilizados para entrenar el modelo.\n",
    "    \"\"\"\n",
    "    # Crear el directorio de salida si no existe\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"Directorio creado: {output_dir}\")\n",
    "\n",
    "    # Identificar el nombre del modelo a partir del archivo Pickle\n",
    "    model_name = os.path.splitext(os.path.basename(model_pickle_path))[0].replace(\"_\", \" \").capitalize()\n",
    "\n",
    "    # Cargar el modelo desde el archivo Pickle\n",
    "    with open(model_pickle_path, \"rb\") as file:\n",
    "        model_data = pickle.load(file)\n",
    "    params = model_data[\"parameters\"]\n",
    "    model = model_data[\"model\"]\n",
    "\n",
    "    # Cargar los datos experimentales\n",
    "    df = pd.read_csv(data_path)\n",
    "    t = df[\"Time (min)\"].values\n",
    "    A = df[\"Average Smoothed\"].values\n",
    "\n",
    "    # Separar datos de entrenamiento y predicción\n",
    "    t_train = t[:n_train]\n",
    "    A_train = A[:n_train]\n",
    "    t_predict = t[n_train:]\n",
    "    A_predict = A[n_train:]\n",
    "\n",
    "    # Predicciones del modelo\n",
    "    A_model = model(t, *params)\n",
    "\n",
    "    # Calcular R^2\n",
    "    r2 = r2_score(A, A_model)\n",
    "\n",
    "    # Crear la gráfica\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Colores personalizados\n",
    "    colors = {\n",
    "        \"Modelo ajustado\": \"#0077b6\",  # Azul oscuro\n",
    "        \"Datos entrenamiento\": \"#ff006e\",  # Fucsia\n",
    "        \"Datos predicción\": \"#ffca3a\"  # Amarillo pastel\n",
    "    }\n",
    "\n",
    "    # Graficar modelo ajustado en todo el rango\n",
    "    plt.plot(\n",
    "        t, A_model,\n",
    "        color=colors[\"Modelo ajustado\"],\n",
    "        label=\"Modelo ajustado\",\n",
    "        linewidth=3,\n",
    "        zorder=2,\n",
    "    )\n",
    "\n",
    "    # Graficar datos de entrenamiento\n",
    "    plt.scatter(\n",
    "        t_train, A_train,\n",
    "        color=colors[\"Datos entrenamiento\"],\n",
    "        label=\"Datos de entrenamiento\",\n",
    "        s=80,\n",
    "        alpha=0.9,\n",
    "        zorder=3,\n",
    "    )\n",
    "\n",
    "    # Graficar datos de predicción\n",
    "    plt.scatter(\n",
    "        t_predict, A_predict,\n",
    "        color=colors[\"Datos predicción\"],\n",
    "        label=\"Datos de predicción\",\n",
    "        s=80,\n",
    "        alpha=0.9,\n",
    "        zorder=3,\n",
    "    )\n",
    "\n",
    "    # Mostrar R^2 directamente en la gráfica\n",
    "    plt.text(\n",
    "        0.05, 0.95, f\"$R^2 = {r2:.4f}$\",\n",
    "        fontsize=16,\n",
    "        color=\"black\",\n",
    "        transform=plt.gca().transAxes,\n",
    "        ha=\"left\", va=\"top\",\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"gray\", facecolor=\"white\")\n",
    "    )\n",
    "\n",
    "    # Personalización de la gráfica\n",
    "    plt.title(f\"{model_name}\", fontsize=20, fontweight=\"bold\", color=\"#023047\")\n",
    "    plt.suptitle(\"Visualización de Entrenamiento y Predicción\", fontsize=14, color=\"gray\")\n",
    "    plt.xlabel(\"Tiempo (min)\", fontsize=14, color=\"#6c757d\")\n",
    "    plt.ylabel(\"Absorbancia (u.a.)\", fontsize=14, color=\"#6c757d\")\n",
    "    plt.xticks(fontsize=12, color=\"#6c757d\")\n",
    "    plt.yticks(fontsize=12, color=\"#6c757d\")\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.6, color=\"#b0b0b0\")\n",
    "\n",
    "    # Mostrar leyenda por defecto\n",
    "    plt.legend(fontsize=12, loc=\"best\", frameon=True, facecolor=\"white\", edgecolor=\"gray\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Guardar la gráfica\n",
    "    output_file = os.path.join(output_dir, f\"{model_name.replace(' ', '_')}_comparison.png\")\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()\n",
    "    print(f\"Gráfica guardada en: {output_file}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Directorios\n",
    "models_dir = \"../files/models\"\n",
    "data_path = \"../files/output/data_clean.csv\"\n",
    "output_dir = \"../files/plots\"\n",
    "\n",
    "# Iterar sobre los archivos en la carpeta models\n",
    "for model_file in os.listdir(models_dir):\n",
    "    if model_file.endswith(\".pkl\"):  # Procesar solo archivos .pkl\n",
    "        model_path = os.path.join(models_dir, model_file)\n",
    "        graf_and_save(\n",
    "            model_pickle_path=model_path,\n",
    "            data_path=data_path,\n",
    "            output_dir=output_dir,\n",
    "            n_train=n_train\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
